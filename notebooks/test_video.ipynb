{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger la vidéo d'origine\n",
    "input_video_path = \"test_videos/football_video.mp4\"  # Remplace par le chemin de ta vidéo\n",
    "output_video_path = \"test_videos/match_football_10fps.mp4\"\n",
    "\n",
    "# Ouvrir la vidéo\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# Vérifier si la vidéo est bien chargée\n",
    "if not cap.isOpened():\n",
    "    print(\"Erreur lors du chargement de la vidéo.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vidéo convertie à 10 FPS sauvegardée sous : test_videos/match_football_10fps.mp4\n"
     ]
    }
   ],
   "source": [
    "# Obtenir les propriétés de la vidéo\n",
    "original_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "frame_size = (frame_width, frame_height)\n",
    "\n",
    "# Définir le codec et initialiser l'enregistreur vidéo\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Codec pour le format MP4\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, 10, frame_size)\n",
    "\n",
    "# Lire et écrire les frames à 10 FPS\n",
    "frame_interval = original_fps // 10  # Intervalle pour sélectionner les frames\n",
    "\n",
    "frame_count = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Écrire uniquement les frames à l'intervalle défini\n",
    "    if frame_count % frame_interval == 0:\n",
    "        out.write(frame)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# Libérer les ressources\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"Vidéo convertie à 10 FPS sauvegardée sous : {output_video_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have the video in 10 FPS for less computation power needs, let us start the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger la vidéo\n",
    "input_video_path = \"test_videos/match_football_10fps.mp4\"\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# Vérifier si la vidéo est bien chargée\n",
    "if not cap.isOpened():\n",
    "    print(\"Erreur lors du chargement de la vidéo.\")\n",
    "    exit()\n",
    "\n",
    "# Lire la première frame\n",
    "ret, frame = cap.read() # Lis uniquement la première frame, ret est un booléen\n",
    "if ret:\n",
    "    # Convertir la frame (OpenCV -> PIL)\n",
    "    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    image.show()  # Affiche la première frame comme une image\n",
    "else:\n",
    "    print(\"Erreur lors de la lecture de la première frame.\")\n",
    "\n",
    "# Libérer les ressources pour l'instant\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle et le processeur\n",
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
    "\n",
    "# Préparer l'image pour le modèle\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Convertir les outputs en format COCO\n",
    "target_sizes = torch.tensor([image.size[::-1]])  # Taille de l'image (H, W)\n",
    "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
    "\n",
    "# Annoter l'image avec PIL\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Optionnel : Charger une police pour le texte\n",
    "try:\n",
    "    font = ImageFont.truetype(\"arial.ttf\", size=15)\n",
    "except IOError:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "# Dessiner les boîtes et les labels\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    x_min, y_min, x_max, y_max = map(int, box)\n",
    "\n",
    "    # Dessiner le rectangle\n",
    "    draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\", width=3)\n",
    "\n",
    "    # Ajouter le label et le score\n",
    "    label_text = f\"{model.config.id2label[label.item()]}: {round(score.item(), 2)}\"\n",
    "    text_bbox = draw.textbbox((0, 0), label_text, font=font)\n",
    "    text_width = text_bbox[2] - text_bbox[0]\n",
    "    text_height = text_bbox[3] - text_bbox[1]\n",
    "    text_bg = [x_min, y_min - text_height, x_min + text_width, y_min]\n",
    "\n",
    "    draw.rectangle(text_bg, fill=\"red\")\n",
    "    draw.text((x_min, y_min - text_height), label_text, fill=\"white\", font=font)\n",
    "\n",
    "# Afficher l'image annotée\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It works with one frame so let's do it for the entire video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 frames traitées...\n",
      "20 frames traitées...\n",
      "30 frames traitées...\n",
      "40 frames traitées...\n",
      "50 frames traitées...\n",
      "60 frames traitées...\n",
      "70 frames traitées...\n",
      "80 frames traitées...\n",
      "90 frames traitées...\n",
      "100 frames traitées...\n",
      "110 frames traitées...\n",
      "120 frames traitées...\n",
      "130 frames traitées...\n",
      "140 frames traitées...\n",
      "150 frames traitées...\n",
      "Toutes les frames ont été annotées.\n"
     ]
    }
   ],
   "source": [
    "# Réinitialiser le lecteur de vidéo\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# Créer une liste pour stocker les frames annotées\n",
    "annotated_frames = []\n",
    "\n",
    "frame_count = 0  # Compteur pour suivre le nombre de frames traitées\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Fin de la vidéo\n",
    "\n",
    "    # Convertir la frame OpenCV en PIL.Image\n",
    "    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Passer l'image au modèle\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Post-traitement des résultats\n",
    "    target_sizes = torch.tensor([image.size[::-1]])\n",
    "    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
    "\n",
    "    # Annoter l'image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "        box = [round(i, 2) for i in box.tolist()]\n",
    "        x_min, y_min, x_max, y_max = map(int, box)\n",
    "        draw.rectangle([x_min, y_min, x_max, y_max], outline=\"red\", width=3)\n",
    "        label_text = f\"{model.config.id2label[label.item()]}: {round(score.item(), 2)}\"\n",
    "        text_bbox = draw.textbbox((0, 0), label_text, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]\n",
    "        text_height = text_bbox[3] - text_bbox[1]\n",
    "        text_bg = [x_min, y_min - text_height, x_min + text_width, y_min]\n",
    "        draw.rectangle(text_bg, fill=\"red\")\n",
    "        draw.text((x_min, y_min - text_height), label_text, fill=\"white\", font=font)\n",
    "\n",
    "    # Ajouter la frame annotée à la liste (convertir PIL -> OpenCV)\n",
    "    annotated_frame = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "    annotated_frames.append(annotated_frame)\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % 10 == 0:\n",
    "        print(f\"{frame_count} frames traitées...\")\n",
    "\n",
    "cap.release()\n",
    "print(\"Toutes les frames ont été annotées.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to save all the frames in one video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La vidéo annotée a été sauvegardée sous : annotated_football_video.mp4\n"
     ]
    }
   ],
   "source": [
    "# Spécifiez le chemin de sortie pour la vidéo annotée\n",
    "output_video_path = \"results/videos/annotated_football_video.mp4\"\n",
    "\n",
    "# Définir les propriétés de la vidéo de sortie (format, FPS, dimensions)\n",
    "frame_height, frame_width, _ = annotated_frames[0].shape  # Taille de la première frame\n",
    "fps = 10  # Choisir 10 FPS comme spécifié\n",
    "\n",
    "# Initialiser le VideoWriter\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Codec pour MP4\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Ajouter chaque frame annotée à la vidéo\n",
    "for frame in annotated_frames:\n",
    "    out.write(frame)\n",
    "\n",
    "# Libérer les ressources\n",
    "out.release()\n",
    "\n",
    "print(f\"La vidéo annotée a été sauvegardée sous : {output_video_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
